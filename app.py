import streamlit as st
import pandas as pd
from io import BytesIO

st.set_page_config(page_title="Debug de Merge", layout="wide")

COLUNAS_PADRAO = [
    "NumeroInstalacaoUsina", "DistribuidoraNome", "PromotorNome", "Nome", "Email", 
    "Documento", "RgNumero", "Telefone", "NumeroInstalacao", "NumeroCliente", 
    "Fornecimento", "ModalidadeCompensacao", "KwhContratado", "TarifaDesconto", 
    "Endereco", "EnderecoNumero", "EnderecoComplemento", "EnderecoCidade", 
    "EnderecoCep", "EnderecoUf", "EnderecoBairro", "DataNascimento", 
    "DataAssinaturaContrato", "Observacao", "ValidacaoInfosDistribuidora", 
    "DescricaoValidacaoInfosDistribuidora", "WhatsappNotificacao", 
    "DevolucaoPisCofins", "DevolucaoFioB", "DevolucaoIcms", "CreditoResidual"
]

# --- KEYS PARA MERGE DAS PLANILHAS ---
CHAVE_A = "NÃºmero da InstalaÃ§Ã£o"
CHAVE_B = "UC"

# Mapeamento de colunas destino e origem da tabela A e B
MAPEAMENTO_A = {
    "NumeroInstalacaoUsina": "NÃºmero de InstalaÃ§Ã£o do Gerador",
    "DistribuidoraNome": "Distribuidora_A",
    "PromotorNome": "Parceiro",
    "Nome": "Titular",
    "Email": "E-mails do Consumidor Final",
    "Documento": "Documento do Consumidor Final (CPF ou CNPJ da Matriz)",
    "Telefone": "Telefones do Consumidor Final",
    "NumeroInstalacao": "NÃºmero da InstalaÃ§Ã£o",
    "NumeroCliente": "NÃºmero do Cliente",
    "ModalidadeCompensacao": "Modalidade de CompensaÃ§Ã£o",
    "KwhContratado": "kWh Contratado",
    "TarifaDesconto": "Desconto na Tarifa(%)",
    "Endereco": "EndereÃ§o_A",
    "EnderecoNumero": "NÃºmero (EndereÃ§o)",
    "EnderecoComplemento": "Complemento_A",
    "EnderecoCidade": "Cidade_A",
    "EnderecoCep": "CEP_A",
    "EnderecoUf": "UF",
    "EnderecoBairro": "Bairro_A",
    "DataNascimento": "Data de Nascimento_A",
    "DataAssinaturaContrato": "Data de Assinatura", 
    "Observacao": "ObservaÃ§Ãµes da InstalaÃ§Ã£o", 
    "ValidacaoInfosDistribuidora": "Status da ValidaÃ§Ã£o das Credenciais da Distribuidora", 
    "DescricaoValidacaoInfosDistribuidora": "InformaÃ§Ã£o da ValidaÃ§Ã£o das Credenciais da Distribuidora",
    "WhatsappNotificacao": "Envio de fatura via Whatsapp habilitado?", 
    "DevolucaoPisCofins": "Restituir Impostos",
    "DevolucaoFioB": "Restituir Fio B",
    # "DevolucaoIcms": "Restituir Impostos",
    # "CreditoResidual": ""
}

MAPEAMENTO_B = {
    "RgNumero": "NÃšMERO DO RG",
    "Fornecimento": "TIPO DE LIGAÃ‡ÃƒO",
}

st.title("ðŸ“‘ Cadastro em massa Ecotech")

# --- BLOCO DE EXPLICAÃ‡ÃƒO ---
st.markdown("""
Esta ferramenta automatiza a unificaÃ§Ã£o de dados entre a planilha de **Prosumidores (Digital Grid)** e a de **NegÃ³cios (Bitrix)**. 
O objetivo Ã© gerar um arquivo padronizado para o sistema de cadastro em massa de prosumidores, na Ecotech.

**Como funciona:**
1. **Upload:** FaÃ§a o upload da planilha A (Prosumidores DG) e planilha B (NegÃ³cios Bitrix *que vc deseja cadastrar*).
> Lembre-se de filtrar apenas os que deseja cadastrar e ativar todas as colunas no Bitrix antes de exportar o CSV.
2. **Cruzamento:** O sistema busca a correspondÃªncia entre o *NÃºmero da InstalaÃ§Ã£o* (DG) e a *UC* (Bitrix).
3. **Prioridade:** Mantemos todos os registros da **planilha B (Bitrix)** e buscamos os dados complementares na DG.
4. **Limpeza:** CPF/CNPJ sÃ£o limpos (apenas nÃºmeros) e as datas sÃ£o formatadas para o padrÃ£o brasileiro.
5. **Download:** O resultado Ã© um arquivo CSV pronto, seguindo o layout oficial de colunas da Ecotech.
6. **ConferÃªncia:** Por fim, confira os dados gerados e preencha os faltantes, caso hajam, antes de importar na Ecotech.
---
""")
# -------------------------------

col1, col2 = st.columns(2)
with col1:
    file_a = st.file_uploader("Planilha A (Prosumidores DG)", type=["csv", "xlsx"])
with col2:
    file_b = st.file_uploader("Planilha B (NegÃ³cios Bitrix)", type=["csv"])

if file_a and file_b:
    try:
        # Leitura das planilhas
        df_a = pd.read_excel(file_a) if file_a.name.endswith('.xlsx') else pd.read_csv(file_a, sep=None, engine='python')
        df_b = pd.read_csv(file_b, sep=None, engine='python')

        # --- BLOCO DE SEGURANÃ‡A: NORMALIZAÃ‡ÃƒO ---
        # ForÃ§a os IDs a serem strings, remove espaÃ§os e converte para nÃºmero (se possÃ­vel) para igualar formatos
        def limpar_id(serie):
            return serie.astype(str).str.replace(r'\.0$', '', regex=True).str.strip()

        df_a[CHAVE_A] = limpar_id(df_a[CHAVE_A])
        df_b[CHAVE_B] = limpar_id(df_b[CHAVE_B])

        # --- DEBUG DE COLUNAS ---
        # with st.expander("ðŸ•µï¸ Clique para ver os nomes das colunas encontradas"):
        #     st.write("**Colunas na Planilha A:**", df_a.columns.tolist())
        #     st.write("**Colunas na Planilha B:**", df_b.columns.tolist())

        # MERGE
        df_unificado = pd.merge(df_a,
                                df_b,
                                left_on=CHAVE_A,
                                right_on=CHAVE_B,
                                how='right',
                                suffixes=('_A', '_B'), # Colunas repetidas ganharÃ£o estes sufixos
                                indicator=True)

        # --- RELATÃ“RIO DE ERROS ---
        matches = df_unificado[df_unificado['_merge'] == 'both']
        falhas = df_unificado[df_unificado['_merge'] == 'right_only']

        # Armazena as chaves das ocorrÃªncias que nÃ£o deram certo
        chaves_que_falharam = falhas[CHAVE_B].unique().tolist()

        st.subheader("ðŸ“Š Resultado do Cruzamento")
        col1, col2 = st.columns(2)
        col1.metric("Sucesso (Bitrix x DG)", len(matches))
        col2.metric("Falha (NÃ£o encontrados dados correspondentes na DG)", len(falhas))

        # Exibe as chaves das falhas no front
        if len(falhas) > 0:
            with st.expander("âš ï¸ Ver UCs da Planilha B (Bitrix) nÃ£o encontrados na Planilha A (DG)"):
                st.write(f"Os seguintes IDs da coluna '{CHAVE_B}' nÃ£o possuem correspondÃªncia:")
                st.write(chaves_que_falharam)

        if len(matches) > 0:
            st.write("âœ… **Exemplo de dados que deram certo:**")
            # Mostra a chave e as colunas que vocÃª quer puxar da A
            cols_to_show = [CHAVE_B] + [v for v in MAPEAMENTO_A.values() if v in df_unificado.columns]
            st.dataframe(matches[cols_to_show].head(5))
        else:
            st.error("ðŸš¨ NENHUM MATCH ENCONTRADO! Os IDs da Planilha A nÃ£o batem com os da B.")
            st.write("Compare os IDs abaixo:")
            st.write(f"IDs na A (exemplo): {df_a[CHAVE_A].head(3).tolist()}")
            st.write(f"IDs na B (exemplo): {df_b[CHAVE_B].head(3).tolist()}")

        if st.button("Gerar Arquivo Final"):
            # Cria o DataFrame vazio com o cabeÃ§alho padrÃ£o
            df_final = pd.DataFrame(columns=COLUNAS_PADRAO)
            
            # Define a chave principal vinda da Planilha B
            df_final["NumeroCliente"] = df_unificado[CHAVE_B]

            # Preenchimento Planilha A
            for col_f, col_o in MAPEAMENTO_A.items():
                if col_o in df_unificado.columns:
                    df_final[col_f] = df_unificado[col_o]
                else:
                    st.warning(f"Coluna de origem '{col_o}' (Planilha A) nÃ£o encontrada.")

            # Preenchimento Planilha B
            for col_f, col_o in MAPEAMENTO_B.items():
                if col_o in df_unificado.columns:
                    df_final[col_f] = df_unificado[col_o]
                else:
                    st.warning(f"Coluna de origem '{col_o}' (Planilha B) nÃ£o encontrada.")

            # CORREÃ‡ÃƒO PARA COLUNAS DUPLICADAS (Mesma origem para destinos diferentes)
            # AtribuÃ­mos manualmente para evitar o erro de "Duplicate column names"
            if "DevolucaoPisCofins" in df_final.columns:
                df_final["DevolucaoIcms"] = df_final["DevolucaoPisCofins"]

            # Limpezas e FormataÃ§Ãµes Finais
            if "Documento" in df_final.columns:
                df_final["Documento"] = df_final["Documento"].astype(str).str.replace(r'\D', '', regex=True)
            
            for col_data in ["DataNascimento", "DataAssinaturaContrato"]:
                if col_data in df_final.columns:
                    df_final[col_data] = pd.to_datetime(df_final[col_data], errors='coerce').dt.strftime('%d/%m/%Y')

            # --- ETAPA DE TRANSFORMAÃ‡ÃƒO DE DADOS ---
            # 1. Mapeamento Sim/NÃ£o para TRUE/FALSE
            mapa_bool = {"Sim": True, "NÃ£o": False, "SIM": True, "NÃƒO": False, "nao": False, "sim": True}

            cols_booleanas = [
                "WhatsappNotificacao", 
                "DevolucaoPisCofins", 
                "DevolucaoFioB", 
                "DevolucaoIcms",
                "CreditoResidual"
            ]

            for col in cols_booleanas:
                if col in df_final.columns:
                    # Aplica o mapeamento e garante que valores vazios ou diferentes fiquem como False
                    df_final[col] = df_final[col].map(mapa_bool).fillna(False)

            # 2. ForÃ§ar Valor Fixo para ValidaÃ§Ã£o
            df_final["ValidacaoInfosDistribuidora"] = False

            # 3. FormataÃ§Ã£o de Datas (DD/MM/AAAA -> AAAA-MM-DD)
            cols_datas = ["DataNascimento", "DataAssinaturaContrato"]

            for col in cols_datas:
                if col in df_final.columns:
                    # Converte para datetime e depois formata como string ISO (AAAA-MM-DD)
                    df_final[col] = pd.to_datetime(df_final[col], dayfirst=True, errors='coerce').dt.strftime('%Y-%m-%d')
                    # Caso a data seja invÃ¡lida na origem, o resultado serÃ¡ 'NaN' ou string vazia
                    df_final[col] = df_final[col].fillna("")

            # 4. FormataÃ§Ã£o de KwhContratado (Ex: 799,99999 -> 799.99)
            if "KwhContratado" in df_final.columns:
                # Garante que Ã© string, troca vÃ­rgula por ponto
                df_final["KwhContratado"] = df_final["KwhContratado"].astype(str).str.replace(',', '.')
                
                # Converte para numÃ©rico (coerce transforma erros em NaN)
                df_final["KwhContratado"] = pd.to_numeric(df_final["KwhContratado"], errors='coerce')
                
                # Arredonda para 2 casas decimais e preenche vazios com 0.00
                df_final["KwhContratado"] = df_final["KwhContratado"].round(2).fillna(0.00)

            # 5. FormataÃ§Ã£o de Documento (Ex: 12312312312 -> 123123123-12)
            if "Documento" in df_final.columns:
                # Primeiro, limpamos tudo que nÃ£o Ã© nÃºmero e garantimos que Ã© string
                df_final["Documento"] = df_final["Documento"].astype(str).str.replace(r'\D', '', regex=True)
                
                # Aplicamos a mÃ¡scara: tudo atÃ© o penÃºltimo caractere + '-' + dois Ãºltimos caracteres
                # Apenas se o campo nÃ£o estiver vazio
                df_final["Documento"] = df_final["Documento"].apply(
                    lambda x: f"{x[:-2]}-{x[-2:]}" if len(x) > 2 else x
                )
            # ---------------------------------------

            # ExportaÃ§Ã£o
            st.success("Tabela final gerada com sucesso! Baixe para obter todos os dados.")
            st.dataframe(df_final.head()) # Preview final para conferÃªncia

            output = BytesIO()
            df_final.to_csv(output, index=False, sep=';', encoding='utf-8-sig')
            st.download_button("ðŸ“¥ Baixar CSV", output.getvalue(), "resultado.csv", "text/csv")

    except Exception as e:
        st.error(f"Erro crÃ­tico: {e}")